{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '/projects/data/kinetics_dataset/k400/annotations'\n",
    "kinetics_path = '../datas/dgx_native/finetune/revised/k400'\n",
    "os.makedirs(kinetics_path,exist_ok=True)\n",
    "data_path = '/home/runner/shared/ganzorig/data/kinetics_dataset/k400/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id = pd.read_csv(os.path.join(my_path,'kinetics_400_labels.csv'),usecols=['id','name'])\n",
    "label2id ={}\n",
    "for index, row in label_id.iterrows():\n",
    "    label2id[row['name']] = row['id']\n",
    "    #label2id[name] = id\n",
    "\n",
    "#my_path = '/projects/data/kinetics_dataset/k400/'\n",
    "for i in ['train.csv','test.csv','val.csv']:\n",
    "#for i in ['test.csv']:\n",
    "\n",
    "    rows = []\n",
    "    with open(os.path.join(kinetics_path,i),'w',newline ='') as file_write:\n",
    "        writer = csv.writer(file_write)\n",
    "        data = pd.read_csv(os.path.join(my_path,i),usecols=['label','youtube_id','time_start','time_end'])\n",
    "        for index, row in data.iterrows():\n",
    "            #print(row['label'], row['youtube_id'], type(row['time_start']),type(row['time_end']))\n",
    "            assert row['time_start']< row['time_end']\n",
    "            #print(row['youtube_id'] + '_'+ '0'*(6-len(str(row['time_start'])))+str(row['time_start']) + '_'+ '0'*(6-len(str(row['time_end'])))+str(row['time_end'])  + '.mp4')  \n",
    "            video_path = row['youtube_id'] + '_'+ '0'*(6-len(str(row['time_start'])))+str(row['time_start']) + '_'+ '0'*(6-len(str(row['time_end'])))+str(row['time_end'])  + '.mp4'\n",
    "            label = label2id[row['label']]\n",
    "\n",
    "            #print(video_path,label)\n",
    "\n",
    "            #path, label = path_label.split()\n",
    "            path = data_path+i.split('.')[0]+'/'+video_path\n",
    "            #print(path,label)\n",
    "            if os.path.exists(path):\n",
    "                writer.writerow([path+' '+str(label)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '/projects/data/kinetics_dataset/k400/'\n",
    "\n",
    "for i in ['train.csv','test.csv','val.csv']:\n",
    "    rows = []\n",
    "    with open(os.path.join(kinetics_path,'revised','k400',i),'w',newline ='') as file_write:\n",
    "        writer = csv.writer(file_write)\n",
    "        with open(os.path.join(kinetics_path,i)) as f:\n",
    "            for path_label in f.read().splitlines():\n",
    "                #print(path_label)\n",
    "                path, label = path_label.split()\n",
    "                path = my_path+i.split('.')[0]+'/'+path.split('/')[1]\n",
    "                print(path,label)\n",
    "                writer.writerow([path+' '+label])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#for i in ['train.csv','test.csv','val.csv']:\n",
    "for i in ['train.csv']:\n",
    "    rows = []\n",
    "\n",
    "    data = pd.read_csv(os.path.join(kinetics_path,i),header=None,index_col=False)\n",
    "#    for idx , path in data:\n",
    "#        print(idx,path)\n",
    "\n",
    "    for i in data:\n",
    "        print(i)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '/projects/data/kinetics_dataset/k400/annotations'\n",
    "kinetics_path = '../datas/dgx/pretrain/k400'\n",
    "os.makedirs(kinetics_path,exist_ok=True)\n",
    "data_path = '/projects/data/kinetics_dataset/k400/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrain data path for Kinetics400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_path = '/projects/data/kinetics_dataset/k400/'\n",
    "for i in ['train.csv','test.csv','val.csv']:\n",
    "#for i in ['test.csv']:\n",
    "\n",
    "    rows = []\n",
    "    with open(os.path.join(kinetics_path,i),'w',newline ='') as file_write:\n",
    "        writer = csv.writer(file_write)\n",
    "        data = pd.read_csv(os.path.join(my_path,i),usecols=['label','youtube_id','time_start','time_end'])\n",
    "        for index, row in data.iterrows():\n",
    "            #print(row['label'], row['youtube_id'], type(row['time_start']),type(row['time_end']))\n",
    "            assert row['time_start']< row['time_end']\n",
    "            #print(row['youtube_id'] + '_'+ '0'*(6-len(str(row['time_start'])))+str(row['time_start']) + '_'+ '0'*(6-len(str(row['time_end'])))+str(row['time_end'])  + '.mp4')  \n",
    "            video_path = row['youtube_id'] + '_'+ '0'*(6-len(str(row['time_start'])))+str(row['time_start']) + '_'+ '0'*(6-len(str(row['time_end'])))+str(row['time_end'])  + '.mp4'\n",
    "\n",
    "            path = data_path+i.split('.')[0]+'/'+video_path #+', 0, -1, 0'\n",
    "            #print(path,label)\n",
    "            writer.writerow([path,0 , -1 , 0])#+\"\\, 0\\, -1\\, 0\"]) # video_path, 0, -1, 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nla-slr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
